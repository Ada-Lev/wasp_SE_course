# WASP SE2024: Essay on AI Engineering.
Dominik Drexler
Linköping University

# 1.  Introduction
I am a fourth-year WASP PhD student at Linköping University. My research is in the intersection of artificial intelligence (AI) planning and learning. AI planning involves making rational choices to help an agent achieve its goal, given a symbolic model of how the world works. These models are often intractable, meaning that general solvers cannot efficiently solve them in polynomial time. However, an agent capable of learning from past experiences can overcome this limitation by acquiring knowledge that aids in solving problems efficiently. A core assumption in my research is that the problems are drawn from infinitely large classes of problems that have general polynomial time solution strategies, i.e., they are not NP-hard. A significant issue with many current AI systems, such as neural networks, is their large number of parameters, which complicates understanding their outputs and reusing them. Neural networks, trained bottom-up, often result in weak generalization capabilities, falling short of full coverage. To address these limitations, my research focuses on learning representations of general solution strategies using simple, well-defined target languages like first-order logic, description logic, and classical planning. We have demonstrated that the subgoal structure of many classical planning domains can be learned, effectively decomposing problems into smaller, efficiently solvable subproblems. We have also developed methods to learn hierarchical policies by iteratively decomposing problems into subproblems and scaling up learning methods through symmetry reduction using graph isomorphism testing. Additionally, we created methods to test the feature expressivity needed for learning using the Weisfeiler-Leman algorithm and its connection to first-order logics. Our research has led to the development of a large AI system capable of reading and understanding various languages, generating datasets from AI planning input data, and integrating combinatorial and continuous optimization methods. This paper reflects on these challenges and connects them with concepts from the WASP software engineering course.

# 2.  Testing and Technical Dept in AI Research
AI research is rapidly advancing, significantly influencing our daily lives. However, the competitive nature of this field often results in researchers not thoroughly testing their software, leading to lower software quality and significant technical and mental debt. This section argues against this approach and advocates for developing reusable and well-tested software libraries.

Neglecting to write tests for software can lead to difficult-to-identify errors when changes are made, significantly slowing down future research and prototyping, thereby creating technical debt. Additionally, identifying the root causes of these errors requires considerable mental effort, leading to mental debt. Making methods accessible to other researchers becomes problematic if changes introduce errors, especially since others may not be familiar with the implementation details.

Researchers often avoid writing tests due to the significant time investment required, with little immediate reward when the primary goal is to publish new research ideas. Early-career researchers, in particular, are measured by the novelty and quality of their methods rather than the reliability of their software. However, as researchers progress in their careers, it is crucial to reevaluate this strategy and consider the long-term benefits of thorough testing.

Senior researchers play a crucial role in promoting better software practices by prioritizing testing, creating discussions on writing effective tests, and investing resources in developing software and tests by hiring dedicated personnel. Increased emphasis on testing and discussions about its importance can lead to higher-quality research outputs and more robust software.

# 3.  Code smells
One common code smell is the plain-old-data-type (PODT) smell, which occurs when a basic type, such as an integer, is used to represent a value with a specific unit, like meters. This can lead to significant issues when such input arguments are exposed in the public application programming interface (API), resulting in programming errors when units do not match. This makes the software harder to understand and debug because it disables static error checking. Even large companies, such as Volve, sometimes fail to use or develop libraries that handle these problems elegantly.

Glue code is often necessary to translate data for processing by different libraries. Preventing extensive use of glue code from the outset is challenging because the final product's features are often unknown during initial development. Developers must find general abstractions for the concepts used in their software to avoid code duplication and minimize glue code. In AI planning, we work with vast amounts of information represented as various types of graphs, running algorithms to extract insights from these structures. Implementing appropriate abstractions can significantly reduce technical debt by promoting code reuse.

# 4.  Behavioral Software Engineering (BSE)
There is a growing number of AI tools available for software engineering. Examples include GitHub Copilot, which generates code that fits the given context, and ChatGPT, which can be used to query answers for general programming questions. These tools are incredibly valuable because they can quickly inspect code, understand it, and provide feedback. They can also help users quickly comprehend other people's code by offering explanations. However, there is skepticism among professionals about the increasing role of AI in software engineering. Experienced individuals often do not use these tools due to their lack of reliable understanding and potential to output incorrect results. Instead, they prefer to consult library documentations directly.

# 5.  Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding
The paper “Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding” [1] investigates whether applying SOLID design principles to machine learning (ML) code improves code understanding. A controlled experiment with 100 data scientists demonstrated that SOLID principles significantly enhance the readability and maintainability of ML code. This is crucial for the engineering of AI systems, which require clear and maintainable code for long-term sustainability. By adhering to SOLID principles, such as the Single Responsibility Principle (SRP), Open-Closed Principle (OCP), Liskov Substitution Principle (LSP), Interface Segregation Principle (ISP), and Dependency Inversion Principle (DIP), ML code can be made more modular, flexible, and easier to debug, test, and extend.

The paper’s findings are highly relevant as they emphasize the importance of structured and maintainable code, which is essential for integrating various AI components and ensuring the system's reliability. Applying SOLID principles can aid in creating well-defined interfaces and modular components, making it easier to incorporate learning algorithms, planning modules, and other AI functionalities. This structured approach is crucial for developing robust and scalable AI systems that can adapt to new requirements and integrate other software libraries. For example, Boost graph library (BGL) is a large and efficient library to run algorithms on various types of graphs. However, BGL does not natively support backward traversal of edges. Hence, we decided to tag a graph with a direction to be able to decide on the traversal direction at compile time. Such a tagged graph has just one responsibility, namely to dispatch the correct overloads, but has a huge impact on the expressiveness of the library.

In a larger AI-intensive software project, applying SOLID principles would improve the project's maintainability and scalability. My research can benefit from this by ensuring that the AI planning and learning components are well-structured and easy to extend. The structured code would facilitate collaboration among researchers and enable seamless integration of new features. For example, if the AI system needs to integrate new machine learning models or data processing pipelines, following SOLID principles would allow these additions to be made with minimal changes to existing code, reducing the risk of introducing bugs and ensuring that the system remains stable and reliable.

Additionally, the modularization encouraged by SOLID principles would enable different teams to work on separate components without causing conflicts, streamlining the development process and improving productivity. For instance, one team could focus on enhancing the planning algorithm while another works on optimizing the learning model, both benefiting from a clear and well-defined interface between components.

My research could be adapted to incorporate SOLID principles by modularizing the AI components and clearly defining their responsibilities. This would enhance the system's robustness and make it easier to test and maintain. Additionally, adopting these principles would facilitate better collaboration with other researchers, leading to more efficient development and deployment of AI systems.

By adopting these principles, my research could contribute to developing a more structured and maintainable AI system. This would not only improve the quality of the code but also make it easier to onboard new team members, facilitate debugging and testing, and ensure that the system can be easily extended with new functionalities. This approach would ultimately lead to the creation of robust and scalable AI systems that can effectively adapt to the evolving needs of AI research and industry applications.

# 6.  Design Patterns for AI-based Systems: A Multivocal Literature Review and Pattern Repository
The paper "Design Patterns for AI-based Systems: A Multivocal Literature Review and Pattern Repository" [2] provides an extensive review and categorization of design patterns used in AI-based systems. The core ideas include cataloging AI-specific design patterns and creating a web-based repository to make these patterns easily accessible and browsable for both researchers and practitioners. This structured documentation enhances system quality, maintainability, and scalability by offering proven, reusable solutions to common problems. The identified patterns are categorized into architecture, deployment, implementation, security and safety, process, testing and quality assurance, and topology, offering a comprehensive overview of design solutions in AI engineering.

The patterns identified in the paper can directly enhance my work. For example, the "Workflow Pipeline" pattern can help structure the integration of learning and planning components, ensuring a systematic and scalable approach. Similarly, "Encapsulating ML Models within Rule-based Safeguards" can enhance the reliability of AI planning systems by providing a framework to handle errors and adversarial attacks effectively.

In a larger AI-intensive software project, my research on AI planning can benefit from these design patterns. By implementing patterns like "AI Pipelines," I can structure the flow of data and processes in a way that enhances modularity and maintainability. This is particularly useful for handling complex planning tasks that require decomposition into subproblems, a core aspect of my research. Additionally, the use of "Two-Phase Predictions" can optimize the execution of large, complex models by splitting the prediction process, thus improving efficiency and response times.

The alignment of my research with these design patterns ensures that the AI planning systems I develop are not only effective in solving problems but also scalable and robust in real-world applications. This integration allows for a more seamless deployment of AI planning solutions, which can be critical for projects that demand high reliability and performance

To further enhance AI engineering in such projects, my research methods can be adapted to fit within these design patterns. For example, developing specific learning modules that align with "Workflow Pipeline" can streamline the integration of planning and learning processes. Additionally, documenting and sharing learned hierarchical policies and subgoal structures within the pattern repository can contribute valuable insights and solutions to the broader research community.

By continuously refining these methods and incorporating feedback from the application of these patterns, I can ensure that my AI planning systems remain at the forefront of efficiency and adaptability. This ongoing improvement process is essential for keeping up with the evolving challenges in AI engineering and ensuring the practical applicability of my research.

# 7. Conclusions
In conclusion, integrating structured software engineering practices and design patterns specific to AI-based systems is essential for developing reliable and scalable AI solutions. My research on AI planning and learning benefits significantly from these practices, enhancing the efficiency and robustness of intelligent agents. By adopting these principles, researchers can create modular, adaptable, and high-quality AI systems.

# Literature
[1] Cabral, R., Kalinowski, M., Baldassarre, M. T., Villamizar, H., Escovedo, T., & Lopes, H. (2024). Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding. arXiv. [https://arxiv.org/abs/2402.05337](https://arxiv.org/abs/2402.05337)

[2] Heiland, L., Hauser, M., & Bogner, J. (2023). Design Patterns for AI-based Systems: A Multivocal Literature Review and Pattern Repository. arXiv. [https://arxiv.org/abs/2303.13173](https://arxiv.org/abs/2303.13173)
